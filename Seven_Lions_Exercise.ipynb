{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NisAchal/simple_image_augmentation/blob/main/Seven_Lions_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Seven Lions Exercise"
      ],
      "metadata": {
        "id": "7UjRq0gOuCJH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this exercise, you will practice implementing data augmentation techniques on a sample image of a lion. In addition to the original image, you will generate six lions using augmentation. \n",
        "\n",
        "We've written the exercise for PyTorch, but you're welcome to use any alternative library for image augmentation you could use. In fact, YOLOv5 uses [Albumentation](https://albumentations.ai/). Refer to this [PyTorch page](https://pytorch.org/vision/main/transforms.html) for more information on PyTorch's data augmentation techniques."
      ],
      "metadata": {
        "id": "aMfM7B9dtwZq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtXPDK3rw-ym"
      },
      "outputs": [],
      "source": [
        "#Import libraries\n",
        "\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms as T"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set parameters\n",
        "\n",
        "plt.rcParams[\"savefig.bbox\"] = 'tight'\n",
        "torch.manual_seed(0) #for randomly applied transforms"
      ],
      "metadata": {
        "id": "hWGzi_etw-yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Lion #1"
      ],
      "metadata": {
        "id": "zpEqXRx1xCTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Display original image\n",
        "##Note: Upload the image of the lion to the Session Storage (under Files). You may need to adjust the path.\n",
        "#Hint: Use .show() to display the image \n"
      ],
      "metadata": {
        "id": "cZ0f8idEw-yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Lion #2"
      ],
      "metadata": {
        "id": "0Z7x_R_-xIHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Display the shape of the image\n",
        "##Hint: Convert the image to an array using the np.asarray() method\n"
      ],
      "metadata": {
        "id": "NSYyRyu4w-yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Resize the original image to be 128 x 128 \n",
        "##Hint: Use the Resize transform\n"
      ],
      "metadata": {
        "id": "6Qiyi_XLw-yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Lion #3"
      ],
      "metadata": {
        "id": "86L7XqQLxUka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Grayscale the original image\n",
        "##Hint: Use the Grayscale transform\n"
      ],
      "metadata": {
        "id": "gsQvHzyGw-yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Lion #4"
      ],
      "metadata": {
        "id": "w4ZnBYjvxaPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Rotate the original image\n",
        "##Hint: Use the RandomRotation transform\n"
      ],
      "metadata": {
        "id": "XgjCBDrOw-yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Lion #5"
      ],
      "metadata": {
        "id": "izLMpjlBxdwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reflect (flip) the original image\n",
        "##Hint: Use the RandomHorizontalFlip transform\n"
      ],
      "metadata": {
        "id": "pVlFaa3kw-yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Lion #6"
      ],
      "metadata": {
        "id": "3WUgtYwOxinn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize the original image\n",
        "##Hint: Use the Normalize transform\n",
        "##Hint: You'll need to convert the image to a Tensor image (and then convert back to a PIL image to display)\n",
        "##Note: PyTorch uses the means and standard deviations of ImageNet in its documentation\n"
      ],
      "metadata": {
        "id": "8WwhrHwxw-yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Lion #7"
      ],
      "metadata": {
        "id": "E_blHDbvxpKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a pipeline of 3 transformations of your choosing and display your final image\n",
        "##Hint: Use torch.nn.Sequential class\n"
      ],
      "metadata": {
        "id": "bHUB0OLHw-yp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}